{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-Basic_Transfer_Learning",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0ctWS-d-ovD"
      },
      "source": [
        "# Basic Transfer Learning with Cats and Dogs Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOWjqHUyCTod"
      },
      "source": [
        "## Import modules and cats and dogs dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcZX4N2s-2Xc",
        "outputId": "a2479047-3741-4b43-f41e-19387a257fec"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print('TensorFlow version: {}'.format(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aftxylVCA6BT"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thokuPYtBo4n",
        "outputId": "7f494ccb-b25a-473d-a243-f920732ff91b"
      },
      "source": [
        "print('TensorFlow version: {}'.format(tf.__version__))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGiRKAhxGS8V"
      },
      "source": [
        "The easiest way to download and save a file is to use the __urllib.request.urlretrieve__ function:\n",
        "\n",
        "- import urllib.request\n",
        "- Download the file from `url` and save it locally under `file_name`:\n",
        "- urllib.request.urlretrieve(url, file_name)\n",
        "\n",
        "\n",
        "Using __shutil.copyfile__.\n",
        "- from shutil import copyfile\n",
        "- copyfile(src, dst)\n",
        "- Copy the contents of the file named src to a file named dst.\n",
        "\n",
        "The OS module in python \n",
        "- Provides functions for interacting with the operating system. \n",
        "- This module provides a portable way of using operating system dependent functionality. \n",
        "- The *os* and *os.path* modules include many functions to interact with the file system.\n",
        "- __os.getcwd()__: returns the Current Working Directory(CWD) of the file used to execute the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d6tMlwhBrmi"
      },
      "source": [
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "\n",
        "from shutil import copyfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wfg_9XApl0o"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QCFtg8EXobSD",
        "outputId": "cf776626-c222-4806-e021-5c8019c503d3"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yod4l4g0jXy5"
      },
      "source": [
        "data_url = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\"\n",
        "data_file_name = \"catsdogs.zip\"\n",
        "download_dir = '/tmp/'\n",
        "\n",
        "urllib.request.urlretrieve(data_url, data_file_name)\n",
        "\n",
        "zip_ref = zipfile.ZipFile(data_file_name, 'r')\n",
        "zip_ref.extractall(download_dir)\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQsGAlz-ubqY"
      },
      "source": [
        "Check that the dataset is the expected number of examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQAQVvy8t31M",
        "outputId": "eb532d9b-82bb-4267-c4df-35a256369e29"
      },
      "source": [
        "print(len(os.listdir('/tmp/PetImages/Cat/')))\n",
        "print(len(os.listdir('/tmp/PetImages/Dog/')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12501\n",
            "12501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEXkMxtzxzow"
      },
      "source": [
        "Create some folders that will store the training and test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRJqR3R5vzce"
      },
      "source": [
        "try:\n",
        "  os.mkdir('/tmp/cats-v-dogs')\n",
        "  os.mkdir('/tmp/cats-v-dogs/training')\n",
        "  os.mkdir('/tmp/cats-v-dogs/testing')\n",
        "  os.mkdir('/tmp/cats-v-dogs/training/cats')\n",
        "  os.mkdir('/tmp/cats-v-dogs/training/dogs')\n",
        "  os.mkdir('/tmp/cats-v-dogs/testing/cats')\n",
        "  os.mkdir('/tmp/cats-v-dogs/testing/dogs')\n",
        "except OSError:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJAm6F8SrFem"
      },
      "source": [
        "Split data into training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4yqs_e9zwpB"
      },
      "source": [
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "def split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):\n",
        "  files = []\n",
        "  for filename in os.listdir(SOURCE):\n",
        "    file = SOURCE + filename\n",
        "    if os.path.getsize(file) > 0:\n",
        "      files.append(filename)\n",
        "    else:\n",
        "      print(filename + \" is zero length, so ignoring.\")\n",
        "\n",
        "  training_length = int(len(files) * SPLIT_SIZE)\n",
        "  testing_length = int(len(files) - training_length)\n",
        "  shuffled_set = random.sample(files, len(files))\n",
        "  training_set = shuffled_set[0:training_length]\n",
        "  testing_set = shuffled_set[:testing_length]\n",
        "\n",
        "  for filename in training_set:\n",
        "    this_file = SOURCE + filename\n",
        "    destination = TRAINING + filename\n",
        "    copyfile(this_file, destination)\n",
        "\n",
        "  for filename in testing_set:\n",
        "    this_file = SOURCE + filename\n",
        "    destination = TESTING + filename\n",
        "    copyfile(this_file, destination)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8U9Q0aUOe_W"
      },
      "source": [
        "CAT_SOURCE_DIR = \"/tmp/PetImages/Cat/\"\n",
        "TRAINING_CATS_DIR = \"/tmp/cats-v-dogs/training/cats/\"\n",
        "TESTING_CATS_DIR = \"/tmp/cats-v-dogs/testing/cats/\"\n",
        "DOG_SOURCE_DIR = \"/tmp/PetImages/Dog/\"\n",
        "TRAINING_DOGS_DIR = \"/tmp/cats-v-dogs/training/dogs/\"\n",
        "TESTING_DOGS_DIR = \"/tmp/cats-v-dogs/testing/dogs/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l7STSsqQHKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bed22c2-3f88-45b7-c302-06dc5928233a"
      },
      "source": [
        "split_size = .9\n",
        "split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)\n",
        "split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "666.jpg is zero length, so ignoring.\n",
            "11702.jpg is zero length, so ignoring.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjcS1agZRFMT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a360faab-d76d-4912-b64f-b68af383e6f3"
      },
      "source": [
        "print(len(os.listdir('/tmp/cats-v-dogs/training/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/training/dogs/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/cats/')))\n",
        "print(len(os.listdir('/tmp/cats-v-dogs/testing/dogs/')))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11250\n",
            "11250\n",
            "1250\n",
            "1250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3IuVf50IpgY"
      },
      "source": [
        "## Preprocessing Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI2XPOqBGR8I"
      },
      "source": [
        "Keras __ImageDataGenerator class__ allows to perform image augmentation.\n",
        "\n",
        "The __ImageDataGenerator class__ has three methods \n",
        "- __flow()__, \n",
        "- __flow_from_directory()__ and \n",
        "- __flow_from_dataframe()__ to read the images from a big numpy array and folders containing images.\n",
        "\n",
        "The folder names (with respective label names) for the classes are important.\n",
        "\n",
        "Here are the most used attributes along with the __flow_from_directory() method__.\n",
        "\n",
        "__train_generator__\n",
        "- __The directory__ must be set to the path where your ‘n’ classes of folders are present.\n",
        "- __The target_size__ is the size of your input images, every image will be resized to this size.\n",
        "- __color_mode__: if the image is either black and white or grayscale set “grayscale” or if the image has three color channels, set “rgb”.\n",
        "- __batch_size__: No. of images to be yielded from the generator per batch.\n",
        "- __class_mode__: Set “binary” if you have only two classes to predict, if not set to“categorical”, in case if you’re developing an Autoencoder system, both input and the output would probably be the same image, for this case set to “input”.\n",
        "- __shuffle__: Set True if you want to shuffle the order of the image that is being yielded, else set False.\n",
        "- __seed__: Random seed for applying random image augmentation and shuffling the order of the image.\n",
        "\n",
        "__valid_generator__\n",
        "- Same as train generator settings except for obvious changes like directory path.\n",
        "\n",
        "\n",
        "__test_generator__\n",
        "- __directory__: path where there exists a folder, under which all the test images are present. For example, in this case, the images are found in /test/test_images/\n",
        "- __batch_size__: Set this to some number that divides your total number of images in your test set exactly.\n",
        "- __class_mode__: Set this to None, to return only the images.\n",
        "- __shuffle__: Set this to False, because you need to yield the images in “order”, to predict the outputs and match them with their unique ids or filenames.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD633csTI9to",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af419e61-2f8c-47a6-efcd-670a3b19e5a7"
      },
      "source": [
        "TRAINING_DIR = \"/tmp/cats-v-dogs/training/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, \n",
        "                                   rotation_range=40, \n",
        "                                   width_shift_range=0.2, \n",
        "                                   height_shift_range=0.2, \n",
        "                                   shear_range=0.2, \n",
        "                                   zoom_range=0.2, \n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR, \n",
        "                                                    batch_size=100, \n",
        "                                                    class_mode='binary', \n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "\n",
        "VALIDATION_DIR = \"/tmp/cats-v-dogs/testing/\"\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, \n",
        "                                                              batch_size=100, \n",
        "                                                              class_mode='binary', \n",
        "                                                              target_size=(150, 150))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 22499 images belonging to 2 classes.\n",
            "Found 2500 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvGBpGDQd0nd"
      },
      "source": [
        "## Get and Prepare the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrljJYbFd5VU"
      },
      "source": [
        "Transfer learning using the `InceptionV3` model.  \n",
        "- You'll load the pre-trained weights of the model.\n",
        "- You'll also freeze the existing layers so that they aren't trained on your downstream task with the cats and dogs data.\n",
        "- You'll also get a reference to the last layer, 'mixed7' because you'll add some layers after this last layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBmCm7uNeSQE",
        "outputId": "6ce49287-067f-4805-eb8b-84135f9c7aea"
      },
      "source": [
        "weights_url = \"https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
        "weights_file = \"inception_v3.h5\"\n",
        "\n",
        "urllib.request.urlretrieve(weights_url, weights_file)\n",
        "\n",
        "# Instantiate the model\n",
        "pre_trained_model = InceptionV3(input_shape=(150, 150, 3),\n",
        "                                include_top=False, \n",
        "                                weights=None)\n",
        "\n",
        "# Load pre-trained weights\n",
        "pre_trained_model.load_weights(weights_file)\n",
        "\n",
        "# Freeze the layers\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Pre_trained_model.summary()\n",
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZrXxfwxKV9M"
      },
      "source": [
        "## Add Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62xyQm-3KVtt"
      },
      "source": [
        "\n",
        "Add some layers that you will train on the cats and dogs data.\n",
        "\n",
        "- __Flatten__: This will take the output of the last_layer and flatten it to a vector.\n",
        "- __Dense__: You'll add a dense layer with a relu activation.\n",
        "- __'Dense'__: After that, add a dense layer with a sigmoid activation. The sigmoid will scale the output to range from 0 to 1, and allow you to interpret the output as a prediction between two categories (cats or dogs).\n",
        "\n",
        "Then create the model object."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Kw1cGf7d4Zx"
      },
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "\n",
        "# Add a fully connected layer with 1.024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "\n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(pre_trained_model.input, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xa1CS3UiNu6p"
      },
      "source": [
        "## Train the model\n",
        "\n",
        "Compile the model and then train it on the test data using model.fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBmjulM6Nx55"
      },
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=RMSprop(lr=0.0001), \n",
        "              loss='binary_crossentropy', \n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDCLL1KngHEv",
        "outputId": "76883f59-e145-4b8f-8a6c-d39a89971f26"
      },
      "source": [
        "# Train the model\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator, \n",
        "    validation_data=validation_generator, \n",
        "    epochs=20, \n",
        "    verbose=1)\n",
        "\n",
        "print()\n",
        "print('Time: {:.2f} minutes'.format((time.time()-start)/60))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "  8/225 [>.............................] - ETA: 2:08 - loss: 1.2887 - acc: 0.7387"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 32 bytes but only got 0. Skipping tag 270\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 5 bytes but only got 0. Skipping tag 271\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 272\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:770: UserWarning: Possibly corrupt EXIF data.  Expecting to read 48 bytes but only got 0. Skipping tag 532\n",
            "  \" Skipping tag %s\" % (size, len(data), tag)\n",
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "225/225 [==============================] - 181s 803ms/step - loss: 0.2350 - acc: 0.9083 - val_loss: 0.0935 - val_acc: 0.9696\n",
            "Epoch 2/20\n",
            "225/225 [==============================] - 179s 794ms/step - loss: 0.1519 - acc: 0.9384 - val_loss: 0.0699 - val_acc: 0.9764\n",
            "Epoch 3/20\n",
            "225/225 [==============================] - 176s 781ms/step - loss: 0.1399 - acc: 0.9442 - val_loss: 0.0740 - val_acc: 0.9744\n",
            "Epoch 4/20\n",
            "225/225 [==============================] - 175s 777ms/step - loss: 0.1345 - acc: 0.9469 - val_loss: 0.0992 - val_acc: 0.9716\n",
            "Epoch 5/20\n",
            "225/225 [==============================] - 176s 783ms/step - loss: 0.1325 - acc: 0.9482 - val_loss: 0.0695 - val_acc: 0.9768\n",
            "Epoch 6/20\n",
            "225/225 [==============================] - 175s 777ms/step - loss: 0.1268 - acc: 0.9507 - val_loss: 0.0715 - val_acc: 0.9776\n",
            "Epoch 7/20\n",
            "225/225 [==============================] - 173s 769ms/step - loss: 0.1198 - acc: 0.9551 - val_loss: 0.0706 - val_acc: 0.9800\n",
            "Epoch 8/20\n",
            "225/225 [==============================] - 172s 765ms/step - loss: 0.1180 - acc: 0.9549 - val_loss: 0.0711 - val_acc: 0.9804\n",
            "Epoch 9/20\n",
            "225/225 [==============================] - 172s 766ms/step - loss: 0.1194 - acc: 0.9552 - val_loss: 0.0889 - val_acc: 0.9684\n",
            "Epoch 10/20\n",
            "225/225 [==============================] - 175s 777ms/step - loss: 0.1162 - acc: 0.9573 - val_loss: 0.0767 - val_acc: 0.9784\n",
            "Epoch 11/20\n",
            "225/225 [==============================] - 176s 783ms/step - loss: 0.1112 - acc: 0.9578 - val_loss: 0.0698 - val_acc: 0.9800\n",
            "Epoch 12/20\n",
            "225/225 [==============================] - 175s 778ms/step - loss: 0.1088 - acc: 0.9586 - val_loss: 0.0702 - val_acc: 0.9800\n",
            "Epoch 13/20\n",
            "225/225 [==============================] - 175s 778ms/step - loss: 0.1082 - acc: 0.9607 - val_loss: 0.0628 - val_acc: 0.9820\n",
            "Epoch 14/20\n",
            "225/225 [==============================] - 175s 776ms/step - loss: 0.1071 - acc: 0.9621 - val_loss: 0.0552 - val_acc: 0.9840\n",
            "Epoch 15/20\n",
            "225/225 [==============================] - 173s 771ms/step - loss: 0.1045 - acc: 0.9618 - val_loss: 0.0629 - val_acc: 0.9832\n",
            "Epoch 16/20\n",
            "225/225 [==============================] - 174s 774ms/step - loss: 0.1047 - acc: 0.9608 - val_loss: 0.0590 - val_acc: 0.9848\n",
            "Epoch 17/20\n",
            "225/225 [==============================] - 173s 768ms/step - loss: 0.1004 - acc: 0.9620 - val_loss: 0.0520 - val_acc: 0.9836\n",
            "Epoch 18/20\n",
            "225/225 [==============================] - 172s 765ms/step - loss: 0.1041 - acc: 0.9620 - val_loss: 0.0545 - val_acc: 0.9844\n",
            "Epoch 19/20\n",
            "225/225 [==============================] - 176s 783ms/step - loss: 0.0997 - acc: 0.9640 - val_loss: 0.0628 - val_acc: 0.9836\n",
            "Epoch 20/20\n",
            "225/225 [==============================] - 175s 777ms/step - loss: 0.0988 - acc: 0.9634 - val_loss: 0.0658 - val_acc: 0.9816\n",
            "\n",
            "Time: 58.73 minutes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmc95lj7iI6l"
      },
      "source": [
        "## Visualize the training and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "FOwDrxl3iY8V",
        "outputId": "f2f89c6f-19d0-45c7-ad51-81867dc1e9fa"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Retrieve a list results on training and test data sets for each training epoch\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc))\n",
        "\n",
        "# Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc, 'r', 'Training Accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', 'Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.figure()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3-ENEs_lMET"
      },
      "source": [
        "## Predict on a test image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "06S917WTl58c",
        "outputId": "2ca05581-4a14-4b27-d05e-d8c0b4e21e09"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # Predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(150, 150))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  image_tensor = np.vstack([x])\n",
        "  classes = model.predict(image_tensor)\n",
        "  print(classes)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a dog\")\n",
        "  else:\n",
        "    print(fn + \" is a cat\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f03b9547-bd85-4ad5-84fe-d4f58d181c44\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f03b9547-bd85-4ad5-84fe-d4f58d181c44\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Captura de tela de 2020-11-30 21-29-54.png to Captura de tela de 2020-11-30 21-29-54.png\n",
            "[[0.]]\n",
            "[0.]\n",
            "Captura de tela de 2020-11-30 21-29-54.png is a cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZWBm_LC-EA1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}